import type { ClothingItem } from '../types/wardrobe';

export interface VirtualTryOnRequest {
  initImage: string;
  referenceImages: string[];
  prompt: string;
  styleInstructions?: string;
  userId: string;
  outfitId: string;
}

export interface VirtualTryOnResult {
  generatedImageUrl: string;
  collageImageUrl?: string;
  processingTime: number;
  confidence: number;
  metadata: {
    prompt: string;
    styleInstructions: string;
    itemsUsed: string[];
    timestamp: string;
  };
}

export interface FluxApiResponse {
  id: string;
  status: 'pending' | 'processing' | 'completed' | 'failed' | 'Ready' | 'Error';
  result?: {
    images?: {
      url: string;
      width: number;
      height: number;
    }[];
    sample?: string;
  };
  error?: string;
  polling_url?: string;
}

export interface TryOnWorkflowState {
  phase:
    | 'input_analysis'
    | 'ai_styling'
    | 'api_transmission'
    | 'output_delivery'
    | 'completed'
    | 'error';
  progress: number;
  message: string;
  data?: any;
}

class VirtualTryOnService {
  private static instance: VirtualTryOnService;

  // Correct Black Forest Labs endpoints according to official docs
  private readonly FLUX_BASE_URL = 'https://api.bfl.ml/v1';
  private readonly API_KEY = process.env.EXPO_PUBLIC_FLUX_API_KEY;
  private readonly MAX_RETRIES = 3;
  private readonly RETRY_DELAY = 2000;

  // Available models based on BFL pricing
  private readonly KONTEXT_PRO_MODEL = 'flux-kontext-pro'; // $0.04 per image - Fast, high-quality editing
  private readonly KONTEXT_MAX_MODEL = 'flux-kontext-max'; // $0.08 per image - Maximum quality
  private readonly STANDARD_PRO_MODEL = 'flux-pro-1.1'; // $0.04 per image - Standard generation
  private readonly DEV_MODEL = 'flux-dev'; // $0.025 per image - Development/testing

  private workflowState: TryOnWorkflowState = {
    phase: 'input_analysis',
    progress: 0,
    message: 'Initializing...',
  };

  private logApiCommunication(
    direction: 'REQUEST' | 'RESPONSE',
    data: {
      timestamp?: string;
      endpoint?: string;
      method?: string;
      headers?: Record<string, string>;
      payload?: any;
      status?: number;
      statusText?: string;
      responseData?: any;
      processingTime?: number;
      error?: string;
    }
  ): void {
    const timestamp = data.timestamp || new Date().toISOString();

    if (direction === 'REQUEST') {
      console.log(
        '\nüöÄ ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê'
      );
      console.log('üì§ AI API REQUEST - VIRTUAL TRY-ON');
      console.log(
        '‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê'
      );

      // Request Summary Table
      const requestSummary = {
        'ÿ≤ŸÖÿßŸÜ ÿßÿ±ÿ≥ÿßŸÑ': timestamp,
        'ŸÖŸÇÿµÿØ API': data.endpoint || 'ŸÜÿßŸÖÿ¥ÿÆÿµ',
        'ŸÜŸàÿπ ÿØÿ±ÿÆŸàÿßÿ≥ÿ™': data.method || 'ŸÜÿßŸÖÿ¥ÿÆÿµ',
        'ÿ≥ÿß€åÿ≤ Payload': data.payload
          ? `${JSON.stringify(data.payload).length} bytes`
          : '0 bytes',
        'ÿ™ÿπÿØÿßÿØ Headers': data.headers ? Object.keys(data.headers).length : 0,
      };

      console.table(requestSummary);

      // Headers Table
      if (data.headers) {
        console.log('\nüìã HEADERS ÿßÿ±ÿ≥ÿßŸÑ€å:');
        const headersTable = Object.entries(data.headers).reduce(
          (acc, [key, value]) => {
            acc[key] =
              key.toLowerCase().includes('key') ||
              key.toLowerCase().includes('token')
                ? `${value.substring(0, 8)}...`
                : value;
            return acc;
          },
          {} as Record<string, string>
        );
        console.table(headersTable);
      }

      // Payload Details
      if (data.payload) {
        console.log('\nüì¶ PAYLOAD ÿ¨ÿ≤ÿ¶€åÿßÿ™:');
        const payloadDetails = {
          Prompt: data.payload.prompt
            ? `${data.payload.prompt.substring(0, 100)}...`
            : 'ŸÜÿØÿßÿ±ÿØ',
          'Image Format': data.payload.image ? 'base64 data URI' : 'ŸÜÿØÿßÿ±ÿØ',
          'Image Size': data.payload.image
            ? `${data.payload.image.length} chars`
            : '0',
          Guidance: data.payload.guidance || 'Ÿæ€åÿ¥ŸÅÿ±ÿ∂',
          'Safety Tolerance': data.payload.safety_tolerance || 'Ÿæ€åÿ¥ŸÅÿ±ÿ∂',
          'Output Format': data.payload.output_format || 'Ÿæ€åÿ¥ŸÅÿ±ÿ∂',
        };
        console.table(payloadDetails);
      }
    } else if (direction === 'RESPONSE') {
      console.log(
        '\nüì• ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê'
      );
      console.log('üì® AI API RESPONSE - VIRTUAL TRY-ON');
      console.log(
        '‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê'
      );

      // Response Summary Table
      const responseSummary = {
        'ÿ≤ŸÖÿßŸÜ ÿØÿ±€åÿßŸÅÿ™': timestamp,
        'Ÿàÿ∂ÿπ€åÿ™ HTTP': data.status || 'ŸÜÿßŸÖÿ¥ÿÆÿµ',
        'ŸÖÿ™ŸÜ Ÿàÿ∂ÿπ€åÿ™': data.statusText || 'ŸÜÿßŸÖÿ¥ÿÆÿµ',
        'ÿ≤ŸÖÿßŸÜ Ÿæÿ±ÿØÿßÿ≤ÿ¥': data.processingTime
          ? `${data.processingTime}ms`
          : 'ŸÜÿßŸÖÿ¥ÿÆÿµ',
        'ŸÜŸàÿπ Ÿæÿßÿ≥ÿÆ': data.responseData ? 'ŸÖŸàŸÅŸÇ' : data.error ? 'ÿÆÿ∑ÿß' : 'ŸÜÿßŸÖÿ¥ÿÆÿµ',
        'ÿ≥ÿß€åÿ≤ Ÿæÿßÿ≥ÿÆ': data.responseData
          ? `${JSON.stringify(data.responseData).length} bytes`
          : '0 bytes',
      };

      console.table(responseSummary);

      // Success Response Details
      if (data.responseData && !data.error) {
        console.log('\n‚úÖ ÿ¨ÿ≤ÿ¶€åÿßÿ™ Ÿæÿßÿ≥ÿÆ ŸÖŸàŸÅŸÇ:');
        const responseDetails = {
          'Request ID': data.responseData.id || 'ŸÜÿØÿßÿ±ÿØ',
          Status: data.responseData.status || 'ŸÜÿßŸÖÿ¥ÿÆÿµ',
          'Images Count': data.responseData.result?.images?.length || 0,
          'Image URL': data.responseData.result?.images?.[0]?.url
            ? `${data.responseData.result.images[0].url.substring(0, 50)}...`
            : 'ŸÜÿØÿßÿ±ÿØ',
          'Image Dimensions': data.responseData.result?.images?.[0]
            ? `${data.responseData.result.images[0].width}x${data.responseData.result.images[0].height}`
            : 'ŸÜÿßŸÖÿ¥ÿÆÿµ',
          'Polling URL': data.responseData.polling_url ? 'ŸÖŸàÿ¨ŸàÿØ' : 'ŸÜÿØÿßÿ±ÿØ',
        };
        console.table(responseDetails);
      }

      // Error Response Details
      if (data.error) {
        console.log('\n‚ùå ÿ¨ÿ≤ÿ¶€åÿßÿ™ ÿÆÿ∑ÿß:');
        const errorDetails = {
          'ŸÜŸàÿπ ÿÆÿ∑ÿß': data.error.substring(0, 100),
          'HTTP Status': data.status || 'ŸÜÿßŸÖÿ¥ÿÆÿµ',
          'ÿÆÿ∑ÿß€å ⁄©ÿßŸÖŸÑ': data.error,
        };
        console.table(errorDetails);
      }

      console.log(
        '‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n'
      );
    }
  }

  static getInstance(): VirtualTryOnService {
    if (!VirtualTryOnService.instance) {
      VirtualTryOnService.instance = new VirtualTryOnService();
    }
    return VirtualTryOnService.instance;
  }

  private constructor() {
    console.log('üîë FLUX API Key Debug:', {
      hasKey: !!this.API_KEY,
      keyLength: this.API_KEY?.length || 0,
      keyStart: this.API_KEY?.substring(0, 8) || 'undefined',
      rawEnvValue:
        process.env.EXPO_PUBLIC_FLUX_API_KEY?.substring(0, 8) || 'not found',
      platform: this.getPlatform(),
      isWeb: this.isWebEnvironment(),
      isDevelopment: process.env.NODE_ENV === 'development',
    });

    if (!this.API_KEY) {
      console.warn('FLUX API key not configured');
    }

    // Show helpful development message for web environment
    if (this.isWebEnvironment() && process.env.NODE_ENV === 'development') {
      console.info(`
üåê Development Mode - Web Environment Detected

CORS Limitation: External API calls are blocked by browsers for security.

Recommended Testing Approaches:
1. üì± Test on mobile device/simulator (no CORS restrictions)
2. üñ•Ô∏è  Use Expo development build 
3. üîß Run backend server for API proxying
4. üìñ Continue with mock data for UI development

Platform: ${this.getPlatform()}
      `);
    }
  }

  private isWebEnvironment(): boolean {
    // Check if we're running in a web browser (Expo web)
    return typeof window !== 'undefined' && typeof document !== 'undefined';
  }

  private getPlatform(): string {
    if (typeof window !== 'undefined') {
      if (window.location?.hostname === 'localhost') return 'web-dev';
      return 'web';
    }
    return 'native';
  }

  private isCorsError(error: Error): boolean {
    const corsIndicators = [
      'fetch',
      'cors',
      'cross-origin',
      'access-control-allow-origin',
      'preflight',
      'network error',
    ];

    const errorMessage = error.message.toLowerCase();
    const errorName = error.name.toLowerCase();

    return corsIndicators.some(
      indicator =>
        errorMessage.includes(indicator) || errorName.includes(indicator)
    );
  }

  private async generateMockVirtualTryOnResult(
    request: VirtualTryOnRequest
  ): Promise<FluxApiResponse> {
    console.log('üé≠ Generating mock virtual try-on result for development');

    // Simulate processing time
    await new Promise(resolve => setTimeout(resolve, 2000));

    // Create a data URI instead of relying on external services
    const mockImageDataUri = this.createMockImageDataUri(
      request.referenceImages.length
    );

    return {
      id: 'mock-dev-' + Date.now(),
      status: 'completed',
      result: {
        images: [
          {
            url: mockImageDataUri,
            width: 1024,
            height: 1024,
          },
        ],
      },
    };
  }

  private createMockImageDataUri(itemCount: number): string {
    // Create a simple SVG placeholder that doesn't rely on external services
    const svg = `
      <svg width="1024" height="1024" xmlns="http://www.w3.org/2000/svg">
        <rect width="100%" height="100%" fill="#4F46E5"/>
        <text x="50%" y="30%" text-anchor="middle" fill="white" font-family="Arial, sans-serif" font-size="48" font-weight="bold">
          Virtual Try-On Demo
        </text>
        <text x="50%" y="40%" text-anchor="middle" fill="white" font-family="Arial, sans-serif" font-size="32">
          Web Development Mode
        </text>
        <text x="50%" y="50%" text-anchor="middle" fill="white" font-family="Arial, sans-serif" font-size="28">
          CORS Limitation
        </text>
        <text x="50%" y="60%" text-anchor="middle" fill="white" font-family="Arial, sans-serif" font-size="28">
          Test on Mobile Device
        </text>
        <text x="50%" y="70%" text-anchor="middle" fill="white" font-family="Arial, sans-serif" font-size="32">
          ${itemCount} Items Used
        </text>
        <text x="50%" y="85%" text-anchor="middle" fill="white" font-family="Arial, sans-serif" font-size="24">
          üé≠ Mock Result - No API Call Made
        </text>
      </svg>
    `;

    // Convert SVG to data URI
    const encodedSvg = encodeURIComponent(svg);
    return `data:image/svg+xml,${encodedSvg}`;
  }

  async processVirtualTryOn(
    request: VirtualTryOnRequest,
    onProgress?: (state: TryOnWorkflowState) => void
  ): Promise<VirtualTryOnResult> {
    console.log('üöÄ Starting Virtual Try-On Process');
    console.log('üìã Request details:', {
      hasUserImage: !!request.initImage,
      clothingItemsCount: request.referenceImages.length,
    });

    let collageUri = ''; // ÿ®ÿ±ÿß€å ÿ∞ÿÆ€åÿ±Ÿá ⁄©ŸàŸÑÿß⁄ò

    try {
      // Update progress
      onProgress?.({
        phase: 'input_analysis',
        progress: 10,
        message: 'Processing images...',
      });

      // Check if we already have a collage (from Native UI)
      // In native environments, the collage is already created and passed as initImage
      const isNativeCollage =
        (typeof document === 'undefined' || typeof window === 'undefined') &&
        request.initImage &&
        request.referenceImages.length > 0;

      if (isNativeCollage) {
        console.log('üì± Using pre-created native collage');
        collageUri = request.initImage;
      } else {
        console.log('üåê Creating web collage');
        // Web environment - create collage here
        collageUri = await this.createOpenArtStyleCollage(
          request.initImage,
          request.referenceImages
        );
      }

      console.log('‚úÖ Collage ready for processing');

      // 2. Create a detailed prompt for FLUX
      const clothingDescriptions = request.referenceImages
        .map((_, index) => `Item ${index + 1}`)
        .join(', ');

      const enhancedPrompt = `Virtual Try-On Task:

Take the person in this image and dress them in the following clothing items:

${clothingDescriptions}

IMPORTANT INSTRUCTIONS:
1. Keep the person's face, hair, body shape, and skin tone EXACTLY the same
2. Replace their current clothes with ALL the new items listed above
3. Ensure natural fabric draping and realistic shadows
4. Maintain professional fashion photography quality
5. The person should be wearing ALL items in a natural, coordinated way

Style: Professional fashion photography, studio lighting, full body shot
Background: Clean, neutral studio background

Note: You are seeing the person's current photo. Your task is to digitally dress them in the new outfit items while keeping their identity intact.`;

      console.log('üìù Generated collage prompt');

      // Update progress
      onProgress?.({
        phase: 'api_transmission',
        progress: 50,
        message: 'Sending to AI for processing...',
      });

      // 3. Call FLUX API with the collage
      await this.testNetworkConnectivity();

      const fluxResult = await this.callFluxKontextAPI({
        initImageMetadata: await this.analyzeImage(collageUri),
        enhancedPrompt: enhancedPrompt,
      });

      // Update progress
      onProgress?.({
        phase: 'output_delivery',
        progress: 90,
        message: 'Finalizing result...',
      });

      // 4. Process the output
      const result = await this.processOutput(fluxResult, request);

      // Add collage URL to the result
      const enhancedResult: VirtualTryOnResult = {
        ...result,
        collageImageUrl: collageUri,
      };

      // Update progress - completed
      onProgress?.({
        phase: 'completed',
        progress: 100,
        message: 'Virtual try-on completed successfully!',
      });

      console.log('‚úÖ Virtual try-on process completed successfully');
      return enhancedResult;
    } catch (error) {
      console.error('‚ùå Virtual try-on process failed:', error);

      // Update progress - error
      onProgress?.({
        phase: 'error',
        progress: 0,
        message:
          error instanceof Error ? error.message : 'Unknown error occurred',
      });

      throw error;
    }
  }

  private async testNetworkConnectivity(): Promise<void> {
    console.log('üåê Testing network connectivity...');

    try {
      const testResponse = await fetch('https://httpbin.org/status/200', {
        method: 'GET',
        headers: {
          'User-Agent': 'Stylisto/1.0.0',
        },
      });

      if (!testResponse.ok) {
        throw new Error('Basic connectivity test failed');
      }

      console.log('‚úÖ Basic network connectivity: OK');

      // Test Black Forest Labs API accessibility
      try {
        const fluxTestResponse = await fetch(
          `${this.FLUX_BASE_URL}/get_result?id=test`,
          {
            method: 'GET',
            headers: {
              'x-key': this.API_KEY || 'test-key',
              Accept: 'application/json',
            },
          }
        );

        console.log(
          `üîó FLUX API endpoint test: ${fluxTestResponse.status} (endpoint reachable)`
        );
      } catch (fluxError) {
        console.warn(
          '‚ö†Ô∏è FLUX API endpoint test failed:',
          fluxError instanceof Error ? fluxError.message : 'Unknown error'
        );
      }
    } catch (error) {
      console.error('‚ùå Network connectivity test failed:', error);
      throw new Error(
        'Network connectivity issue detected. Please check your internet connection and try again.'
      );
    }
  }

  private async analyzeInputs(request: VirtualTryOnRequest): Promise<any> {
    const startTime = Date.now();

    // Analyze each clothing item to extract details for OpenArt-style prompt
    const referenceImagesMetadata = await Promise.all(
      request.referenceImages.map(async (img: string, index: number) => {
        const metadata = await this.analyzeImage(img);
        // Extract clothing type from URL or use generic description
        const clothingType = this.detectClothingType(img, index);
        return {
          ...metadata,
          description: clothingType,
          index: index + 1,
        };
      })
    );

    const analysis = {
      initImageMetadata: await this.analyzeImage(request.initImage),
      referenceImagesMetadata,
      promptAnalysis: this.analyzePrompt(request.prompt),
      styleContext:
        request.styleInstructions ||
        'natural studio lighting, professional fit',
      processingTime: Date.now() - startTime,
      // OpenArt approach metadata
      itemCount: request.referenceImages.length,
      isMultiItem: request.referenceImages.length > 1,
    };

    console.log('üìä Analysis complete:', {
      userImage: !!analysis.initImageMetadata,
      clothingItems: analysis.itemCount,
      isMultiItem: analysis.isMultiItem,
    });

    return analysis;
  }

  private detectClothingType(imageUrl: string, index: number): string {
    // Simple heuristic to detect clothing type from URL or index
    const url = imageUrl.toLowerCase();

    if (url.includes('shirt') || url.includes('top')) return 'shirt/top';
    if (
      url.includes('pant') ||
      url.includes('trouser') ||
      url.includes('bottom')
    )
      return 'pants/bottoms';
    if (url.includes('shoe') || url.includes('sneaker') || url.includes('boot'))
      return 'shoes/footwear';
    if (url.includes('dress')) return 'dress';
    if (url.includes('jacket') || url.includes('coat'))
      return 'jacket/outerwear';
    if (url.includes('bag') || url.includes('purse')) return 'bag/accessory';

    // Default based on index
    const defaults = ['top/shirt', 'bottom/pants', 'shoes', 'accessory'];
    return defaults[index] || `item ${index + 1}`;
  }

  private async executeAIStyling(analyzedData: any): Promise<any> {
    // OpenArt approach: Enhance the prompt to work with multiple clothing items
    // They likely use a specific prompt structure that tells FLUX to apply ALL items

    const itemDescriptions = analyzedData.referenceImagesMetadata
      .map(
        (item: any, index: number) =>
          `Item ${index + 1}: ${item.description || 'clothing item'}`
      )
      .join(', ');

    const openArtStylePrompt = this.buildOpenArtStylePrompt(
      analyzedData,
      itemDescriptions
    );

    return {
      ...analyzedData,
      enhancedPrompt: openArtStylePrompt,
      technicalSpecs: {
        lighting: 'cinematic studio lighting',
        fit: 'natural draping and precise fit',
        quality: 'magazine-quality, high-resolution',
        style: 'professional fashion photography',
        instruction:
          'Apply ALL clothing items shown to the person, maintaining exact details of each piece',
      },
    };
  }

  private buildOpenArtStylePrompt(
    analyzedData: any,
    itemDescriptions: string
  ): string {
    // OpenArt-style prompt that works with FLUX Kontext
    const basePrompt = analyzedData.promptAnalysis.original;

    return `Virtual try-on transformation: Take the person from the main image and dress them in ALL the clothing items shown. 
    ${itemDescriptions}. 
    CRITICAL INSTRUCTIONS:
    1. Preserve the person's face, hair, body shape, and pose EXACTLY
    2. Apply each clothing item with proper layering (shirt, then jacket, etc.)
    3. Ensure natural fit and realistic fabric draping
    4. Maintain the exact colors, patterns, and details of each clothing piece
    5. Keep the original background unchanged
    6. Professional fashion photography quality with consistent lighting
    The final result should look like a professional e-commerce or fashion shoot.`;
  }

  private async callFluxKontextAPI(stylingData: any): Promise<FluxApiResponse> {
    console.log('üîë FLUX API Key Debug:', {
      hasKey: !!this.API_KEY,
      keyLength: this.API_KEY?.length || 0,
      keyStart: this.API_KEY?.substring(0, 8) || 'undefined',
    });

    if (!this.API_KEY || this.API_KEY === 'bfl_sk_test_1234567890abcdef') {
      console.warn(
        'üö® FLUX API key not configured or using test key - returning mock result'
      );

      await new Promise(resolve => setTimeout(resolve, 2000));

      return {
        id: 'mock-flux-kontext-id-' + Date.now(),
        status: 'completed',
        result: {
          images: [
            {
              url: 'https://via.placeholder.com/1024x1024/4F46E5/FFFFFF?text=Virtual+Try-On+Demo\nGenerated+by+FLUX+Kontext\nAPI+Coming+Soon',
              width: 1024,
              height: 1024,
            },
          ],
        },
      };
    }

    const isValidFormat =
      this.API_KEY.startsWith('bfl_sk_') ||
      /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i.test(
        this.API_KEY
      );

    if (!isValidFormat) {
      console.error(
        '‚ùå Invalid FLUX API key format. Expected either "bfl_sk_" prefix or UUID format',
        'Current key format:',
        this.API_KEY.substring(0, 8)
      );
      throw new Error(
        'Invalid FLUX API key format. Please check your API key from https://dashboard.bfl.ai/'
      );
    }

    console.log(
      '‚úÖ Valid API key format detected:',
      this.API_KEY.startsWith('bfl_sk_') ? 'bfl_sk_' : 'UUID'
    );

    // Try FLUX.1 Kontext API first (preferred for image editing)
    try {
      return await this.callKontextImageEditing(stylingData);
    } catch (kontextError) {
      console.warn(
        '‚ö†Ô∏è Kontext API failed, falling back to standard image generation:',
        kontextError
      );

      // Check if this is a CORS error in web development environment
      if (
        kontextError instanceof Error &&
        this.isCorsError(kontextError) &&
        this.isWebEnvironment() &&
        process.env.NODE_ENV === 'development'
      ) {
        console.warn('üé≠ CORS detected in development - using mock result');
        return await this.generateMockVirtualTryOnResult({
          initImage: '',
          referenceImages:
            stylingData.referenceImagesMetadata?.map(() => '') || [],
          prompt: stylingData.enhancedPrompt || '',
          userId: '',
          outfitId: '',
        });
      }

      // Fallback to standard image generation API
      try {
        return await this.callStandardImageGeneration(stylingData);
      } catch (standardError) {
        // If both APIs fail due to CORS in development, provide mock
        if (
          standardError instanceof Error &&
          this.isCorsError(standardError) &&
          this.isWebEnvironment() &&
          process.env.NODE_ENV === 'development'
        ) {
          console.warn(
            'üé≠ Both APIs blocked by CORS - using mock result for development'
          );
          return await this.generateMockVirtualTryOnResult({
            initImage: '',
            referenceImages:
              stylingData.referenceImagesMetadata?.map(() => '') || [],
            prompt: stylingData.enhancedPrompt || '',
            userId: '',
            outfitId: '',
          });
        }
        throw standardError;
      }
    }
  }

  private async callKontextImageEditing(
    stylingData: any
  ): Promise<FluxApiResponse> {
    const hasInputImage =
      stylingData.initImageMetadata && stylingData.initImageMetadata.base64;

    if (!hasInputImage) {
      throw new Error('No input image available for Kontext editing');
    }

    // OpenArt approach: They might be using a special image format
    // where the user image is the main focus and clothing items are arranged around it
    console.log('üé® Using OpenArt-style virtual try-on approach');
    console.log(
      'üì∏ Reference images count:',
      stylingData.referenceImagesMetadata?.length || 0
    );

    // Use Kontext Pro model (more cost-effective)
    const endpoint = `${this.FLUX_BASE_URL}/${this.KONTEXT_PRO_MODEL}`;

    // Prepare the request payload according to BFL API docs
    // OpenArt likely sends the body image as the main image
    const payload = {
      prompt: stylingData.enhancedPrompt,
      image: `data:image/jpeg;base64,${stylingData.initImageMetadata.base64}`,
      guidance: 3.5, // Higher guidance for better prompt following
      safety_tolerance: 2,
      output_format: 'jpeg',
      // Note: FLUX Kontext doesn't accept multiple images directly
      // OpenArt's trick is in the prompt engineering
    };

    let lastError: Error | null = null;

    for (let attempt = 1; attempt <= this.MAX_RETRIES; attempt++) {
      try {
        console.log(
          `üöÄ FLUX Kontext API Call Attempt ${attempt}/${this.MAX_RETRIES}`
        );
        console.log('üì° Request Details:', {
          endpoint,
          model: this.KONTEXT_PRO_MODEL,
          hasApiKey: !!this.API_KEY,
          keyFormat: this.API_KEY?.substring(0, 8) + '...',
          hasImage: !!payload.image,
          promptLength: payload.prompt.length,
        });

        const controller = new AbortController();
        const timeoutId = setTimeout(() => {
          controller.abort();
        }, 45000);

        const requestTimestamp = new Date().toISOString();
        const requestStartTime = Date.now();

        // Log API Request
        this.logApiCommunication('REQUEST', {
          timestamp: requestTimestamp,
          endpoint,
          method: 'POST',
          headers: {
            'x-key': this.API_KEY || '',
            'Content-Type': 'application/json',
            Accept: 'application/json',
          },
          payload,
        });

        try {
          const response = await fetch(endpoint, {
            method: 'POST',
            headers: {
              'x-key': this.API_KEY || '', // BFL uses x-key header
              'Content-Type': 'application/json',
              Accept: 'application/json',
            },
            body: JSON.stringify(payload),
            signal: controller.signal,
          });

          clearTimeout(timeoutId);
          const processingTime = Date.now() - requestStartTime;

          console.log(
            'üì• Response Status:',
            response.status,
            response.statusText
          );
          console.log(
            'üì• Response Headers:',
            Object.fromEntries(response.headers.entries())
          );

          if (!response.ok) {
            const errorText = await response.text();
            console.error('‚ùå Error Response Body:', errorText);

            // Log Error Response
            this.logApiCommunication('RESPONSE', {
              timestamp: new Date().toISOString(),
              status: response.status,
              statusText: response.statusText,
              processingTime,
              error: errorText,
            });

            if (response.status === 401 || response.status === 403) {
              throw new Error(
                `FLUX API authentication failed. Please check your API key at https://dashboard.bfl.ai/`
              );
            } else if (response.status === 429) {
              throw new Error(
                `FLUX API rate limit exceeded. Please wait before trying again.`
              );
            } else if (response.status >= 500) {
              throw new Error(
                `FLUX API server error (${response.status}). Please try again later.`
              );
            } else {
              throw new Error(
                `FLUX API error: ${response.status} ${response.statusText} - ${errorText}`
              );
            }
          }

          const result = await response.json();
          console.log('‚úÖ FLUX Kontext API Response:', result);

          // Log Success Response
          this.logApiCommunication('RESPONSE', {
            timestamp: new Date().toISOString(),
            status: response.status,
            statusText: response.statusText,
            processingTime,
            responseData: result,
          });

          // BFL API returns an ID that we need to poll for results
          if (!result.id) {
            throw new Error('Invalid response from FLUX API - missing task ID');
          }

          // Wait for completion using the get_result endpoint
          return await this.waitForStandardCompletion(result.id);
        } catch (fetchError) {
          clearTimeout(timeoutId);
          throw fetchError;
        }
      } catch (error) {
        lastError =
          error instanceof Error ? error : new Error('Unknown error occurred');

        // Check for CORS errors specifically
        if (this.isCorsError(lastError) && this.isWebEnvironment()) {
          console.error('üö´ CORS Error Detected in Web Environment');
          throw new Error(
            `CORS error: The FLUX API cannot be called directly from a web browser due to security restrictions. 
            
Solutions:
1. Test on a mobile device where CORS doesn't apply (recommended)
2. Use a backend server to proxy API calls
3. Wait for backend implementation
4. Use Expo development build instead of web

Current environment: ${this.getPlatform()}`
          );
        }

        console.error(
          `‚ùå FLUX Kontext API Attempt ${attempt} failed:`,
          lastError.message
        );

        if (
          error instanceof TypeError &&
          error.message.includes('Failed to fetch')
        ) {
          console.error('üåê Network connectivity issue detected');
          lastError = new Error(
            'Network connectivity issue. Please check your internet connection and try again.'
          );
        } else if (error instanceof Error && error.name === 'AbortError') {
          console.error('‚è±Ô∏è Request timeout detected');
          lastError = new Error(
            'Request timeout. The FLUX API is taking too long to respond.'
          );
        }

        if (attempt < this.MAX_RETRIES) {
          const delayMs = this.RETRY_DELAY * attempt;
          console.log(`‚è≥ Retrying in ${delayMs}ms...`);
          await new Promise(resolve => setTimeout(resolve, delayMs));
        }
      }
    }

    throw lastError || new Error('Failed after all retries');
  }

  private async callStandardImageGeneration(
    stylingData: any
  ): Promise<FluxApiResponse> {
    // Use flux-pro-1.1 for standard generation (same price as kontext-pro)
    const endpoint = `${this.FLUX_BASE_URL}/${this.STANDARD_PRO_MODEL}`;

    const payload: any = {
      prompt: stylingData.enhancedPrompt,
      width: 1024,
      height: 1024,
      steps: 30,
      guidance: 3.5,
      safety_tolerance: 2,
      output_format: 'jpeg',
    };

    // Note: flux-pro-1.1 doesn't support img2img directly
    // If we have an image, we should use kontext instead

    let lastError: Error | null = null;

    for (let attempt = 1; attempt <= this.MAX_RETRIES; attempt++) {
      try {
        console.log(
          `üöÄ FLUX Standard API Call Attempt ${attempt}/${this.MAX_RETRIES}`
        );
        console.log('üì° Request Details:', {
          endpoint,
          model: this.STANDARD_PRO_MODEL,
          hasApiKey: !!this.API_KEY,
          keyFormat: this.API_KEY?.substring(0, 8) + '...',
          promptLength: payload.prompt.length,
        });

        const controller = new AbortController();
        const timeoutId = setTimeout(() => {
          controller.abort();
        }, 45000);

        const requestTimestamp = new Date().toISOString();
        const requestStartTime = Date.now();

        // Log API Request
        this.logApiCommunication('REQUEST', {
          timestamp: requestTimestamp,
          endpoint,
          method: 'POST',
          headers: {
            'x-key': this.API_KEY || '',
            'Content-Type': 'application/json',
            Accept: 'application/json',
          },
          payload,
        });

        try {
          const response = await fetch(endpoint, {
            method: 'POST',
            headers: {
              'x-key': this.API_KEY || '', // BFL uses x-key header
              'Content-Type': 'application/json',
              Accept: 'application/json',
            },
            body: JSON.stringify(payload),
            signal: controller.signal,
          });

          clearTimeout(timeoutId);
          const processingTime = Date.now() - requestStartTime;

          console.log(
            'üì• Response Status:',
            response.status,
            response.statusText
          );

          if (!response.ok) {
            const errorText = await response.text();
            console.error('‚ùå Error Response Body:', errorText);

            // Log Error Response
            this.logApiCommunication('RESPONSE', {
              timestamp: new Date().toISOString(),
              status: response.status,
              statusText: response.statusText,
              processingTime,
              error: errorText,
            });

            if (response.status === 401 || response.status === 403) {
              throw new Error(
                `FLUX API authentication failed. Please check your API key at https://dashboard.bfl.ai/`
              );
            } else if (response.status === 429) {
              throw new Error(
                `FLUX API rate limit exceeded. Please wait before trying again.`
              );
            } else if (response.status >= 500) {
              throw new Error(
                `FLUX API server error (${response.status}). Please try again later.`
              );
            } else {
              throw new Error(
                `FLUX API error: ${response.status} ${response.statusText} - ${errorText}`
              );
            }
          }

          const submitResult = await response.json();
          console.log('‚úÖ FLUX Submit Response:', submitResult);

          // Log Success Response
          this.logApiCommunication('RESPONSE', {
            timestamp: new Date().toISOString(),
            status: response.status,
            statusText: response.statusText,
            processingTime,
            responseData: submitResult,
          });

          if (!submitResult.id) {
            throw new Error('Invalid response from FLUX API - missing task ID');
          }

          // Wait for completion
          return await this.waitForStandardCompletion(submitResult.id);
        } catch (fetchError) {
          clearTimeout(timeoutId);
          throw fetchError;
        }
      } catch (error) {
        lastError =
          error instanceof Error ? error : new Error('Unknown error occurred');

        // Check for CORS errors specifically
        if (this.isCorsError(lastError) && this.isWebEnvironment()) {
          console.error('üö´ CORS Error Detected in Web Environment');
          throw new Error(
            `CORS error: The FLUX API cannot be called directly from a web browser due to security restrictions. 
            
Solutions:
1. Test on a mobile device where CORS doesn't apply (recommended)
2. Use a backend server to proxy API calls
3. Wait for backend implementation
4. Use Expo development build instead of web

Current environment: ${this.getPlatform()}`
          );
        }

        console.error(
          `‚ùå FLUX Standard API Attempt ${attempt} failed:`,
          lastError.message
        );

        if (attempt < this.MAX_RETRIES) {
          const delayMs = this.RETRY_DELAY * attempt;
          console.log(`‚è≥ Retrying in ${delayMs}ms...`);
          await new Promise(resolve => setTimeout(resolve, delayMs));
        }
      }
    }

    throw lastError || new Error('Failed after all retries');
  }

  private async waitForStandardCompletion(
    taskId: string
  ): Promise<FluxApiResponse> {
    const maxWaitTime = 120000; // 2 minutes timeout
    const pollInterval = 3000; // Poll every 3 seconds
    const startTime = Date.now();

    console.log(`üîÑ Polling for standard FLUX task completion: ${taskId}`);

    while (Date.now() - startTime < maxWaitTime) {
      try {
        const controller = new AbortController();
        const timeoutId = setTimeout(() => {
          controller.abort();
        }, 15000);

        const requestTimestamp = new Date().toISOString();
        const requestStartTime = Date.now();
        const pollEndpoint = `${this.FLUX_BASE_URL}/get_result?id=${taskId}`;

        // Log Polling Request
        this.logApiCommunication('REQUEST', {
          timestamp: requestTimestamp,
          endpoint: pollEndpoint,
          method: 'GET',
          headers: {
            'x-key': this.API_KEY || '',
            Accept: 'application/json',
          },
          payload: { taskId },
        });

        try {
          const response = await fetch(pollEndpoint, {
            method: 'GET',
            headers: {
              'x-key': this.API_KEY || '',
              Accept: 'application/json',
            },
            signal: controller.signal,
          });

          clearTimeout(timeoutId);
          const processingTime = Date.now() - requestStartTime;

          if (!response.ok) {
            const errorText = await response.text();
            console.warn(
              `üìä Status check failed: ${response.status} - ${errorText}`
            );

            // Log Polling Error Response
            this.logApiCommunication('RESPONSE', {
              timestamp: new Date().toISOString(),
              status: response.status,
              statusText: response.statusText,
              processingTime,
              error: errorText,
            });

            throw new Error(`Status check failed: ${response.status}`);
          }

          const result: FluxApiResponse = await response.json();
          console.log(`üìä Task status: ${result.status} for ${taskId}`);

          // Log Polling Success Response
          this.logApiCommunication('RESPONSE', {
            timestamp: new Date().toISOString(),
            status: response.status,
            statusText: response.statusText,
            processingTime,
            responseData: result,
          });

          // BFL API uses 'Ready' status when complete
          if (result.status === 'Ready' || result.status === 'completed') {
            console.log(`‚úÖ Task completed successfully: ${taskId}`);
            return {
              ...result,
              status: 'completed',
            };
          }

          if (result.status === 'Error' || result.status === 'failed') {
            console.error(`‚ùå Task failed: ${result.error || 'Unknown error'}`);
            throw new Error(result.error || 'FLUX processing failed');
          }

          console.log(`‚è≥ Task still processing - waiting ${pollInterval}ms`);
          await new Promise(resolve => setTimeout(resolve, pollInterval));
        } catch (fetchError) {
          clearTimeout(timeoutId);
          throw fetchError;
        }
      } catch (error) {
        const errorMessage =
          error instanceof Error ? error.message : 'Unknown error';
        console.warn(`‚ö†Ô∏è Standard polling error:`, errorMessage);

        if (
          error instanceof TypeError ||
          (error instanceof Error && error.name === 'AbortError')
        ) {
          console.log(
            `üîÑ Network issue during polling, retrying in ${pollInterval}ms...`
          );
          await new Promise(resolve => setTimeout(resolve, pollInterval));
        } else {
          await new Promise(resolve => setTimeout(resolve, pollInterval));
        }
      }
    }

    console.error(`‚è∞ Task timeout exceeded ${maxWaitTime}ms`);
    throw new Error(
      'Virtual try-on processing timeout - task took too long to complete'
    );
  }

  private async processOutput(
    fluxResult: FluxApiResponse,
    request: VirtualTryOnRequest
  ): Promise<VirtualTryOnResult> {
    console.log('üé® Processing FLUX output:', fluxResult);

    const imageUrl =
      fluxResult.result?.images?.[0]?.url ||
      fluxResult.result?.sample ||
      'https://via.placeholder.com/1024x1024/4F46E5/FFFFFF?text=Processing+Error';

    return {
      generatedImageUrl: imageUrl,
      processingTime: 0,
      confidence: 0.95,
      metadata: {
        prompt: request.prompt,
        styleInstructions: request.styleInstructions || '',
        itemsUsed: request.referenceImages,
        timestamp: new Date().toISOString(),
      },
    };
  }

  private async analyzeImage(imageUri: string): Promise<any> {
    try {
      const base64Data = await this.convertToBase64(imageUri);
      const dimensions = await this.getImageDimensions(imageUri);

      return {
        uri: imageUri,
        base64: base64Data,
        dimensions,
        format: this.getImageFormat(imageUri),
      };
    } catch (error) {
      console.error('Error analyzing image:', error);
      throw error;
    }
  }

  private analyzePrompt(prompt: string): any {
    return {
      original: prompt,
      wordCount: prompt.split(' ').length,
      hasStyleKeywords: /\b(style|fashion|elegant|casual|formal)\b/i.test(
        prompt
      ),
      hasColorKeywords: /\b(red|blue|green|black|white|pink|purple)\b/i.test(
        prompt
      ),
    };
  }

  private async convertToBase64(imageUri: string): Promise<string> {
    try {
      if (imageUri.startsWith('data:')) {
        return imageUri.split(',')[1];
      }

      if (imageUri.startsWith('http')) {
        const response = await fetch(imageUri);
        if (!response.ok) {
          throw new Error(`HTTP error! status: ${response.status}`);
        }
        const arrayBuffer = await response.arrayBuffer();
        const uint8Array = new Uint8Array(arrayBuffer);
        let binaryString = '';
        for (let i = 0; i < uint8Array.length; i++) {
          binaryString += String.fromCharCode(uint8Array[i]);
        }
        return this.base64Encode(binaryString);
      }

      if (imageUri.startsWith('file://')) {
        const optimizedUri = await this.optimizeImageForApi(imageUri);
        return await this.convertToBase64(optimizedUri);
      }

      throw new Error(`Unsupported image URI format: ${imageUri}`);
    } catch (error) {
      console.error('Error converting image to base64:', error);
      throw new Error(
        `Failed to convert image to base64: ${error instanceof Error ? error.message : 'Unknown error'}`
      );
    }
  }

  private async optimizeImageForApi(imageUri: string): Promise<string> {
    try {
      console.log('üñºÔ∏è Optimizing image for API transmission...');

      const originalDimensions = await this.getImageDimensions(imageUri);
      console.log('üìè Original dimensions:', originalDimensions);

      const maxWidth = 1024;
      const maxHeight = 1024;

      let targetWidth = originalDimensions.width;
      let targetHeight = originalDimensions.height;

      if (targetWidth > maxWidth || targetHeight > maxHeight) {
        const aspectRatio = targetWidth / targetHeight;

        if (targetWidth > targetHeight) {
          targetWidth = maxWidth;
          targetHeight = Math.round(maxWidth / aspectRatio);
        } else {
          targetHeight = maxHeight;
          targetWidth = Math.round(maxHeight * aspectRatio);
        }
      }

      console.log('üéØ Target dimensions:', {
        width: targetWidth,
        height: targetHeight,
      });

      return imageUri;
    } catch (error) {
      console.error('‚ùå Error optimizing image:', error);
      return imageUri;
    }
  }

  private base64Encode(binaryString: string): string {
    const chars =
      'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/';
    let result = '';
    let i = 0;

    while (i < binaryString.length) {
      const a = binaryString.charCodeAt(i++);
      const b = i < binaryString.length ? binaryString.charCodeAt(i++) : 0;
      const c = i < binaryString.length ? binaryString.charCodeAt(i++) : 0;

      const bitmap = (a << 16) | (b << 8) | c;

      result += chars.charAt((bitmap >> 18) & 63);
      result += chars.charAt((bitmap >> 12) & 63);
      result +=
        i - 2 < binaryString.length ? chars.charAt((bitmap >> 6) & 63) : '=';
      result += i - 1 < binaryString.length ? chars.charAt(bitmap & 63) : '=';
    }

    return result;
  }

  private async getImageDimensions(
    imageUri: string
  ): Promise<{ width: number; height: number }> {
    return new Promise((resolve, reject) => {
      if (typeof Image !== 'undefined') {
        const img = new Image();
        img.onload = () => {
          resolve({ width: img.width, height: img.height });
        };
        img.onerror = reject;
        img.src = imageUri;
      } else {
        console.warn(
          'Image constructor not available, using default dimensions'
        );
        resolve({ width: 1024, height: 1024 });
      }
    });
  }

  private getImageFormat(imageUri: string): string {
    if (imageUri.includes('.png') || imageUri.includes('image/png')) {
      return 'png';
    } else if (imageUri.includes('.webp') || imageUri.includes('image/webp')) {
      return 'webp';
    } else {
      return 'jpeg';
    }
  }

  // Helper function to create a collage from multiple images
  private async createImageCollage(imageUrls: string[]): Promise<string> {
    console.log('üé® Creating collage from', imageUrls.length, 'images');

    // For now, we'll use the first image as primary
    // In a full implementation, you'd use a library like jimp or canvas
    // to create a grid layout of all images

    // TODO: Implement actual image stitching logic
    // Example layout for 3-4 images:
    // +-------+-------+
    // | img1  | img2  |
    // +-------+-------+
    // | img3  | img4  |
    // +-------+-------+

    return imageUrls[0]; // Temporary: just return first image
  }

  private async createOpenArtStyleCollage(
    userImage: string,
    clothingItems: string[]
  ): Promise<string> {
    console.log('üé® Creating OpenArt-style collage');
    console.log('üë§ User image:', userImage.substring(0, 50) + '...');
    console.log('üëó Clothing items:', clothingItems.length);

    // TODO: For now, we're using a simplified approach
    // In the future, we can implement one of these solutions:
    // 1. Use a backend service to create collages
    // 2. Use react-native-canvas for native collage creation
    // 3. Use WebView with Canvas API for cross-platform solution

    // Temporary solution: Return user image
    // The Flux API will use the prompt to understand what clothes to add
    console.log('‚ö†Ô∏è Native collage not implemented, using user image only');
    return userImage;
  }

  private async analyzeClothingForDescriptions(
    clothingItems: string[]
  ): Promise<string[]> {
    console.log('üîç Analyzing clothing items for descriptions');

    // In production, send each image to GPT-4 Vision or similar
    // For now, return placeholder descriptions based on common patterns

    const descriptions = clothingItems.map((item, index) => {
      // Extract hints from URL if possible
      const urlLower = item.toLowerCase();

      if (urlLower.includes('dress')) {
        return 'elegant dress with modern cut and flowing fabric';
      } else if (urlLower.includes('shirt') || urlLower.includes('top')) {
        return 'stylish top with comfortable fit';
      } else if (urlLower.includes('pant') || urlLower.includes('trouser')) {
        return 'well-fitted pants with classic design';
      } else if (urlLower.includes('shoe') || urlLower.includes('boot')) {
        return 'fashionable footwear with quality materials';
      } else if (urlLower.includes('bag')) {
        return 'designer handbag with premium finish';
      } else {
        return `clothing item ${index + 1}`;
      }
    });

    return descriptions;
  }

  private generateOpenArtPrompt(
    itemDescriptions: string[],
    originalPrompt: string
  ): string {
    console.log('üìù Generating OpenArt-style prompt');

    const itemList = itemDescriptions
      .map((desc, idx) => `   Item ${idx + 1}: ${desc}`)
      .join('\n');

    return `Virtual Try-On Transformation Instructions:

IMPORTANT: This is a collage image. The person to dress is in the CENTER of the image.
The clothing items are shown in the surrounding areas.

YOUR TASK:
1. Identify the person in the CENTER of the collage
2. Apply ALL the clothing items shown around them
3. Create a professional fashion photograph result

CLOTHING ITEMS TO APPLY:
${itemList}

CRITICAL REQUIREMENTS:
- Use ONLY the person from the CENTER of the image
- Apply ALL clothing items shown in the surrounding squares
- Maintain the person's EXACT facial features, hair, and body proportions
- Ensure natural fabric draping and realistic shadows
- Professional studio lighting
- Magazine-quality output

${originalPrompt ? `\nAdditional instructions: ${originalPrompt}` : ''}

The final result should show the person wearing all specified items in a natural, photorealistic manner.`;
  }

  private async executeAnalysis(
    request: VirtualTryOnRequest,
    onProgress?: (state: TryOnWorkflowState) => void
  ): Promise<any> {
    // Implementation of executeAnalysis method
    // This method should return the analyzed data
    throw new Error('Method not implemented');
  }

  private async executeStyling(
    analyzedData: any,
    onProgress?: (state: TryOnWorkflowState) => void
  ): Promise<any> {
    // Implementation of executeStyling method
    // This method should return the styled data
    throw new Error('Method not implemented');
  }

  private async executeProcessing(
    styledData: any,
    onProgress?: (state: TryOnWorkflowState) => void
  ): Promise<any> {
    // Implementation of executeProcessing method
    // This method should return the processed data
    throw new Error('Method not implemented');
  }

  private async executeEnhancement(
    processedData: any,
    onProgress?: (state: TryOnWorkflowState) => void
  ): Promise<any> {
    // Implementation of executeEnhancement method
    // This method should return the enhanced data
    throw new Error('Method not implemented');
  }

  private async prepareFinalResult(
    enhancedData: any,
    request: VirtualTryOnRequest
  ): Promise<VirtualTryOnResult> {
    // Implementation of prepareFinalResult method
    // This method should return the final result
    throw new Error('Method not implemented');
  }
}

export const useVirtualTryOn = () => {
  const processOutfitTryOn = async (
    outfitId: string,
    userImage: string,
    clothingItems: ClothingItem[],
    onProgress?: (state: TryOnWorkflowState) => void
  ): Promise<VirtualTryOnResult> => {
    const service = VirtualTryOnService.getInstance();

    // Create a simple request - the service will handle the collage creation
    const request: VirtualTryOnRequest = {
      initImage: userImage,
      referenceImages: clothingItems.map(item => item.imageUrl),
      prompt: '', // Empty prompt - will be generated in processVirtualTryOn
      styleInstructions: 'Professional fashion photography',
      userId: 'user-id',
      outfitId,
    };

    return service.processVirtualTryOn(request, onProgress);
  };

  return { processOutfitTryOn };
};
